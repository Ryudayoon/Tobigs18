# -*- coding: utf-8 -*-
"""week3_NaiveBayes_assignment_Dayoon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12WXeEibjW8R9RClvgxvKvxg_dwzaCgHy

# Assignment

# Naive Bayes Classification

## 1. 직접 수식을 작성하여 Naive Bayes 모델을 만들겠습니다.

- 입력문서가 {fast, fly, shoot} 을 주요 단어로 가질때, 이 문서는 얼마의 확률로 어떤 장르로 분류가 될지 알아보겠습니다.
- 주어진 dataset 을 확인해 보기위해 엑셀 파일을 읽습니다.
"""

import numpy as np
import pandas as pd

documents = pd.read_excel('./test_file.xlsx') 
documents

"""### step 1. 단어를 모두 소문자로 바꾸어 줍니다. 
* message 칼럼에 있는 단어들을 모두 소문자로 바꿔주세요.
"""

lower_documents = [string.lower() for string in documents["message"]]

print(lower_documents)

"""### step2. string.punctuation 을 이용해서 특수문자를 제거해주세요.
- string.punctuation 에는 특수문자들이 저장되어있는것을 확인할수 있습니다.
"""

import string
string.punctuation

import re

del_punctuation_documents = []

for words in lower_documents:
    new_string = ''.join([i for i in words if i not in string.punctuation])
    del_punctuation_documents.append(new_string)

print(del_punctuation_documents)

"""### step 3. 단어를 하나씩 띄어쓰기 단위로 쪼개어 줍니다."""

preprocessed_documents=[d.split(' ') for d in del_punctuation_documents]

print(preprocessed_documents)

"""### step 4. 문자를 숫자로 변환해줍니다.
- 이를 위해 CountVectorizer를 사용합니다.
- CountVectorizer는 문서 집합에서 단어 토큰을 생성하고, 각 단어 수를 세어 BOW (Bag of Words) 인코딩한 벡터를 만들어줍니다.

- 문서에 해당단어가 몇번 포함되었는지를 나타낼 때 사용하는 방법입니다.

- 참고 : https://datascienceschool.net/view-notebook/3e7aadbf88ed4f0d87a76f9ddc925d69/

![CountVectorized](https://user-images.githubusercontent.com/68625698/106378540-15d8ed80-63e9-11eb-8604-5c960c274867.PNG)
"""

from sklearn.feature_extraction.text import CountVectorizer
count_vector = CountVectorizer()
count_vector.fit(documents['message'])

doc_array = count_vector.transform(documents['message']).toarray()
doc_array

count_vector.get_feature_names()

# doc_array 배열에 순서에 따라 매치되는 단어를 나타낸다.
count_vector.vocabulary_

frequency_matrix = pd.DataFrame(doc_array, columns = count_vector.get_feature_names())
frequency_matrix

frequency_matrix['count'] = frequency_matrix.sum(axis=1)
frequency_matrix

"""### step 5. 범주형 변수를 dummy변수로 변환해주는 작업(One-Hot Encoding!)을 해주어야합니다.
- label 을 comedy =1, action =0 으로 변환해주세요
"""

documents['label'] = documents['label'].map({'comedy': 1, 'action': 0})

# documents['label'],frequency_matrix 결합
doc = pd.concat([documents['label'],frequency_matrix],axis=1)

doc

"""###  step 6. 나이브 베이즈 계산을 해봅시다!

- 입력문서가 {fast, fly, shoot} 을 주요 단어로 가질때, 이 문서는 얼마의 확률로 어떤 장르로 분류가 될까요? (계산과정을 채워주세요) 
"""

doc = np.array(doc)      # dataframe을 np-array로 변환해줍니다.
                         # return값은 np-matrix가 아니라 np-array입니다.
doc

type(doc)

"""####  P(Y=comedy), P(Y=action) 계산하기"""

# P(Y=comedy)
p_comedy = sum(doc[:,0]==1) / len(doc)

# P(Y=action)
p_action = sum(doc[:,0]==0) / len(doc)

print('p_comedy : ',p_comedy)
print('p_action : ', p_action)

"""#### P(fast=1|comedy=1), P(fly=1|comedy=1), P(shoot=1|comedy=1) 계산하기

* 문서에 두번 등장한 단어 주의
* 조건부 확률 계산식 참고 
"""

# P(fast=1|comedy=1)
p_comedy_fast = (sum(doc[(doc[:, 0] == 1) & (doc[:, 2] >= 1)][:, 2])) / sum(doc[doc[:, 0] == 1][:, -1])

# P(fly=1|comedy=1)
p_comedy_fly = (sum(doc[(doc[:, 0] == 1) & (doc[:, 3] >= 1)][:, 3])) / sum(doc[doc[:, 0] == 1][:, -1])

# P(shoot=1|comedy=1)
p_comedy_shoot = (sum(doc[(doc[:, 0] == 1) & (doc[:, 7] >= 1)][:, 7])) / sum(doc[doc[:, 0] == 1][:, -1])

print('p_comedy_fast : ' , p_comedy_fast)
print('p_comedy_fly : ' , p_comedy_fly)
print('p_comedy_shoot : ' , p_comedy_shoot)

"""#### P(fast=1|action=1), P(fly=1|action=1), P(shoot=1|action=1) 계산하기"""

# P(fast=1|action=1)
p_action_fast = (sum(doc[(doc[:, 0] == 0) & (doc[:, 2] >= 1)][:, 2])) / sum(doc[doc[:, 0] == 0][:, -1])
# P(fly=1|action=1)
p_action_fly = (sum(doc[(doc[:, 0] == 0) & (doc[:, 3] >= 1)][:, 3])) / sum(doc[doc[:, 0] == 0][:, -1])
# P(shoot=1|action=1)
p_action_shoot = (sum(doc[(doc[:, 0] == 0) & (doc[:, 7] >= 1)][:, 7])) / sum(doc[doc[:, 0] == 0][:, -1])

print('p_action_fast : ' , p_action_fast)
print('p_action_fly : ' , p_action_fly)
print('p_action_shoot : ' , p_action_shoot)

"""#### P(Y = comedy| X = fast, fly, shoot) , P(Y = action=1| X = fast, fly, shoot) 값 계산하기"""

#P(Y = comedy| X = fast, fly, shoot)
proba_comedy = p_comedy_fast*p_comedy_fly*p_comedy_shoot*p_comedy

#P(Y = action=1| X = fast, fly, shoot)
proba_action = p_action_fast*p_action_fly*p_action_shoot*p_action

print('proba_comedy', proba_comedy)
print('proba_action', proba_action)

"""### step 7. 라플라스 스무딩
1. P(Y = comedy| X = fast, fly, shoot) => 0
2. P(Y = action| X = fast, fly, shoot) => 0.003606311044327574

- proba_comedy를 보면 p_comedy_shoot의 값인 0으로 인해 확률이 0으로 계산되었다는 것을 확인할 수 있습니다. 이 문제점을 해결해주세요.
"""

# P(fast=1|comedy=1)
p_comedy_fast_L =  (sum(doc[(doc[:, 0] == 1) & (doc[:, 2] >= 1)][:, 2]) + 1) / (sum(doc[doc[:, 0] == 1][:, -1]) + 7)

# P(fly=1|comedy=1)
p_comedy_fly_L =(sum(doc[(doc[:, 0] == 1) & (doc[:, 3] >= 1)][:, 3]) + 1) / (sum(doc[doc[:, 0] == 1][:, -1]) + 7)

# P(shoot=1|comedy=1)
p_comedy_shoot_L = (sum(doc[(doc[:, 0] == 1) & (doc[:, 7] >= 1)][:, 7]) + 1) / (sum(doc[doc[:, 0] == 1][:, -1]) + 7)

print('p_comedy_fast_L : ' , p_comedy_fast_L)
print('p_comedy_fly_L : ' , p_comedy_fly_L)
print('p_comedy_shoot_L : ' , p_comedy_shoot_L)

# P(fast=1|action=1)
p_action_fast_L = (sum(doc[(doc[:, 0] == 0) & (doc[:, 2] >= 1)][:, 2]) + 1) / (sum(doc[doc[:, 0] == 0][:, -1]) + 7)

# P(fly=1|action=1)
p_action_fly_L = (sum(doc[(doc[:, 0] == 0) & (doc[:, 3] >= 1)][:, 3]) + 1) / (sum(doc[doc[:, 0] == 0][:, -1]) + 7)
# P(shoot=1|action=1)
p_action_shoot_L =(sum(doc[(doc[:, 0] == 0) & (doc[:, 7] >= 1)][:, 7]) + 1) / (sum(doc[doc[:, 0] == 0][:, -1]) + 7)

print('p_action_fast_L : ' , p_action_fast_L)
print('p_action_fly_L : ' , p_action_fly_L)
print('p_action_shoot_L : ' , p_action_shoot_L)

#P(Y = comedy| X = fast, fly, shoot)
proba_comedy_L =  p_comedy_fast_L*p_comedy_fly_L*p_comedy_shoot_L*p_comedy

#P(Y = action=1| X = fast, fly, shoot)
proba_action_L = p_action_fast_L*p_action_fly_L*p_action_shoot_L*p_action

print('proba_comedy_L : ', proba_comedy_L)
print('proba_action_L : ', proba_action_L)

"""### => 두개의 값을 비교하면 action 장르일 때 fast, fly, shoot 단어가 더 자주 나온다고 할 수 있다.

## 2. sklearn을 활용한 Naive Bayes Model
- 먼저 수업 시간에 활용했던 날씨와 온도 데이터를 활용해보겠습니다.
"""

weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',
'Rainy','Sunny','Overcast','Overcast','Rainy']
temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']

play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']

df = pd.DataFrame({'weather':weather, 'temperature':temp, 'play':play})
df

"""### step 1. 문자를 Label Encoding 해줍니다."""

from sklearn.preprocessing import LabelEncoder

"""
라벨 인코더를 생성, fitting하여 
weather, temp, play 에 대해 라벨 인코딩 해주세요.
"""

le = LabelEncoder()

cols = ['weather', 'temperature', 'play']
#
# Encode labels of multiple columns at once
#
df[cols] = df[cols].apply(LabelEncoder().fit_transform)

df.head()

weather_encoded = df['weather'].values
temp_encoded = df['temperature'].values
label = df['play'].values
print("weather:", weather_encoded)
print("Temp:",temp_encoded)
print("Play:",label)

features = list(zip(weather_encoded,temp_encoded))
print(features)

"""### step 2. sklearn의 Naive Bayes 모델인 MultinomialNB를 사용하여 예측하겠습니다.
- weather = 0(Overcast), temp = 2(Mild)인 경우 play = Yes로 예측됩니다.
"""

from sklearn.naive_bayes import MultinomialNB

# 라플라스 스무딩(alpha = 1)
model = MultinomialNB(alpha=1)

# Train the model using the training sets
model.fit(features,label)

#Predict Output
predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild
print("Predicted Value:", predicted) # 1: Yes

"""### 이제 sklearn의 와인 데이터를 바탕으로 MultinomialNB를 활용하여 예측해주세요!
- train과 test 비율은 8:2로 해주세요.
- metrics는 accuracy로 진행해주세요.
"""

from sklearn import datasets

#Load dataset
wine = datasets.load_wine()

# print the names of the 13 features
print("Features: ", wine.feature_names)

# print the label type of wine(class_0, class_1, class_2)
print("Labels: ", wine.target_names)

data=pd.concat([pd.DataFrame({'Labels':wine.target}),pd.DataFrame(wine.data, columns = wine.feature_names)], axis=1)
data

from sklearn.model_selection import train_test_split

"""
X_train, X_test, y_train, y_test로 train_test_split 해주세요.
"""

X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size = 0.2, random_state = 1)

from sklearn.naive_bayes import MultinomialNB
"""
train data로 모델을 생성, 학습시켜주세요. 
"""

clf = MultinomialNB()
y_pred = clf.fit(X_train, y_train).predict(X_test)
print(y_pred)
print(y_test.values)

from sklearn.metrics import accuracy_score

"""
test data로, accuracy를 이용하여 성능을 확인해주세요.
"""
score=accuracy_score(y_true=y_test,y_pred=y_pred)


print("Accuracy:", score)

